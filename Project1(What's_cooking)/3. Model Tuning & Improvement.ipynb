{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*-coding: utf-8-*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, nltk\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer     \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json('train.json')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>All_of_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>romaine lettuce:black olives:grape tomatoes:ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>plain flour:ground pepper:salt:tomatoes:ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>eggs:pepper:salt:mayonaise:cooking oil:green c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>water:vegetable oil:wheat:salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>black pepper:shallots:cornflour:cayenne pepper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "                                  All_of_ingredients  \n",
       "0  romaine lettuce:black olives:grape tomatoes:ga...  \n",
       "1  plain flour:ground pepper:salt:tomatoes:ground...  \n",
       "2  eggs:pepper:salt:mayonaise:cooking oil:green c...  \n",
       "3                     water:vegetable oil:wheat:salt  \n",
       "4  black pepper:shallots:cornflour:cayenne pepper...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['All_of_ingredients'] = train['ingredients'].map(':'.join)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(train['cuisine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model improvement & Tuning\n",
    " \n",
    " * TfidfVectorizer로 하고 앙상블 방법을 적용 시켰을 때 성능이 더 좋음\n",
    "     * => 전처리 방법은 TfidfVectorizer로 진행, 모델은 앙상블 모델 적용.\n",
    " * Logistic C : 정규화 정도를 어느정도 해야 할까?\n",
    " * SVM C : 정규화 정도를 어느정도 해야 할까?\n",
    " \n",
    " * stop_words를 사용할 것인지 안할 것인지?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "       \n",
    "    stemming = [stemmer.lemmatize(ingredients) for ingredients in tokens]\n",
    "    \n",
    "    return stemming\n",
    "\n",
    "def tokenizer(words):\n",
    "\n",
    "    filter_words = re.sub(r'[^a-zA-Z]', \" \", words)\n",
    "    tokens = nltk.word_tokenize(filter_words)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words= ['brazil', 'best', 'ic', 'kim', 'alum', 'bushi','old', 'pla', 'wax', 'truv', 'tip', 'kha',\n",
    "           'petit','classic', 'tie', 'mole', 'diet', 'navel','preserv', 'ume', 'soi', 'uncle','bengali','shin',\n",
    "           'rom', 'southwest', 'jerk','cool','p','minute','added', 'port','rome','french','extra','bloody','black',\n",
    "           'tokyo','cap','edible', 'winter','kong', 'noir','hoi','texas','wagon','frank','non',\n",
    "           'farmer','artisan','rock','peasant','el','dutch', 'bragg','romano','cara','blood','rins',\n",
    "           'nutritional','fast','spanish','ring','sheet','white','season','thai','prime','enriched','helix',\n",
    "           'activ','wood','lotus','america','pain','concentrate','spare','vre','color','mark','single',\n",
    "           'hot', 'machine','greek','london','hidden','silver','ra','tot','moisture','tree','snow','m','di','dr','mex',\n",
    "           'n','seven','balance','cracked','split','hand','yellow','unflavored','asian','shaving','deli','rise','jack',\n",
    "           'softened','hero','cooking','dri','aka','golden', 'cane','elbow','mo','mi','mr','india','lan','green',\n",
    "           'imo','runny','navy','orang','ha','leav','eau','smart','well','plain','angled','korean','steel','farm','stock',\n",
    "           'challenge','baby','lea','long','trumpet','chunk','siu','tap','island','bird','curl','young','shape','pace','napa',\n",
    "           'believ','fiber','food','vie','haas','eye','te','oz','on','world','dark','summer','or','ruby','a','quick',\n",
    "           'head','o','jose','cortland','clarified','full','himalayan', 'free','japanese','holy','blue','new','straw','olek','shoot',\n",
    "           'earth', 'fire','acting','fri','lean','i','celtic','multi','ch','layer','well','gray','won','ngo','le','lb','la','lo',\n",
    "           'bing','imitation', 'pam', 'one','bibb','rich','cloud','cho','age','cup','kasu','swiss','ready','straight','yu','fu','jimmy'\n",
    "           'clear','self','aged','mountain','everglades','part','mission','rocket', 'cross','game','lower','devil','b',\n",
    "           'energy','style','good','hard','paper','brown','diamond','bag', 'bai', 'bar','bob', 'torn','not','mae', \n",
    "           'finger', 'submarine', 'chua', 'it', 'in', 'hong', 'hanh','tyson','with','pod', 'pop','angel','four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear')\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('vect1', TfidfVectorizer(analyzer='word', tokenizer=tokenizer)),\n",
    "        ('clf', ens),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf__svm__random_state',\n",
       " 'vect1__decode_error',\n",
       " 'clf__lr__dual',\n",
       " 'clf__lr__C',\n",
       " 'vect1__encoding',\n",
       " 'clf__lr__solver',\n",
       " 'clf__svm__C',\n",
       " 'vect1__max_df',\n",
       " 'vect1__strip_accents',\n",
       " 'clf__svm__tol',\n",
       " 'clf__lr__verbose',\n",
       " 'clf__svm__kernel',\n",
       " 'clf__lr__n_jobs',\n",
       " 'vect1__stop_words',\n",
       " 'clf__svm__max_iter',\n",
       " 'vect1__dtype',\n",
       " 'clf__svm__gamma',\n",
       " 'clf',\n",
       " 'clf__svm__coef0',\n",
       " 'clf__lr__max_iter',\n",
       " 'vect1__lowercase',\n",
       " 'clf__weights',\n",
       " 'vect1__binary',\n",
       " 'clf__lr__fit_intercept',\n",
       " 'vect1',\n",
       " 'clf__lr__warm_start',\n",
       " 'vect1__input',\n",
       " 'clf__svm',\n",
       " 'clf__mnb__fit_prior',\n",
       " 'clf__voting',\n",
       " 'vect1__ngram_range',\n",
       " 'vect1__use_idf',\n",
       " 'clf__lr__multi_class',\n",
       " 'clf__lr__penalty',\n",
       " 'vect1__max_features',\n",
       " 'clf__lr__intercept_scaling',\n",
       " 'clf__mnb__alpha',\n",
       " 'clf__svm__shrinking',\n",
       " 'vect1__smooth_idf',\n",
       " 'clf__lr__class_weight',\n",
       " 'clf__mnb__class_prior',\n",
       " 'clf__svm__cache_size',\n",
       " 'vect1__sublinear_tf',\n",
       " 'vect1__analyzer',\n",
       " 'clf__lr__random_state',\n",
       " 'clf__svm__decision_function_shape',\n",
       " 'vect1__vocabulary',\n",
       " 'vect1__preprocessor',\n",
       " 'clf__mnb',\n",
       " 'clf__lr',\n",
       " 'vect1__norm',\n",
       " 'clf__n_jobs',\n",
       " 'vect1__min_df',\n",
       " 'vect1__token_pattern',\n",
       " 'steps',\n",
       " 'clf__estimators',\n",
       " 'clf__svm__probability',\n",
       " 'clf__svm__verbose',\n",
       " 'clf__lr__tol',\n",
       " 'clf__svm__degree',\n",
       " 'vect1__tokenizer',\n",
       " 'clf__svm__class_weight']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grids = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "parameters = {\n",
    "    'vect1__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect1__stop_words': [stop_words, None],\n",
    "    'clf__svm__C' : param_grids,\n",
    "    'clf__lr__C' : param_grids}\n",
    "    \n",
    "gs_clf = GridSearchCV(train_clf, parameters,  n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train.All_of_ingredients.tolist()[:3900], y[:3900])\n",
    "gs_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{name}: {best}\".format(\n",
    "        name=param_name, best=best_parameters[param_name]\n",
    "        ))\n",
    "print(\"-\" * 30)\n",
    "print('score :', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 원래는 grid search를 이용한 모델 튜닝 Process를 진행하려고 하였지만 여러번 시도해 본 결과 물리적으로 불가능 했음.\n",
    "    * 좀 더 수준을 올려서 Score를 올릴 계획.\n",
    "    * 다른 모델도 공부해서 모델 적용 할 계획\n",
    "    \n",
    "* 그래서 하나하나씩 여러 경우의 수를 따져서 모델링을 해보고 Score를 측정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 10,  9, ..., 13,  5, 13], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.All_of_ingredients.tolist(), y, test_size = 0.2)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 0.1)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                stop_words = stop_words, ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train1 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 0.1)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                stop_words = stop_words, ngram_range=(1,2))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train2 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 0.1)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                 ngram_range=(2,6))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train3 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 0.1)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                 ngram_range=(2,6))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train4 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.01)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 0.1)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train5 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.01)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 0.1)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,2))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train6 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 10)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                stop_words = stop_words, ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train7 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 10)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train8 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 10)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                stop_words = stop_words, ngram_range=(2,6))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train9 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 10)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(2,6))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train10 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 10)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(2,6))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train11 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 10)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                stop_words = stop_words, ngram_range=(2,6))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train12 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 10)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,2))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train13 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 10)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(2,3))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train14 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 100)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train15 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 100)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,2))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train16 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.1)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 100)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train17 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 10)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 100)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train18 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.01)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 100)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train19 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 0.001)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 100)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train20 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C= 100)\n",
    "mnb = MultinomialNB()\n",
    "svm = SVC(probability=True, kernel = 'linear', C = 100)\n",
    "ens = VotingClassifier(estimators=[('lr', logistic), ('mnb', mnb), ('svm', svm)], voting='soft', weights = [3,1,1])\n",
    "\n",
    "train_clf = Pipeline([\n",
    "        ('tv' , TfidfVectorizer(analyzer = 'word', tokenizer = tokenizer, \n",
    "                                ngram_range=(1,1))),\n",
    "        ('clf', ens)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_train21 = train_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.732872407291012"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67291011942174728"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59157762413576365"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59597737272155882"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72080452545568829"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65191703331238215"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train6.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77272155876807036"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train7.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77498428661219354"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train8.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67642991829038346"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train9.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68698931489629167"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train10.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6595851665619108"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train11.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65267127592708984"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train12.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75876807039597738"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train13.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70622250157133881"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train14.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77121307353865498"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train15.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75826524198617218"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train16.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72558139534883725"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train17.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best Model(model_train18)\n",
    "\n",
    "    * Score = 0.78466373350094276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78466373350094276"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train18.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70245128849780014"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train19.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72847265870521682"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train20.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808925204274042"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train21.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
